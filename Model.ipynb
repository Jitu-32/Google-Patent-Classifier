{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eRn2MKPGrSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.layers import GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import Concatenate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KKie0-5lDqi",
        "colab_type": "text"
      },
      "source": [
        "#### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm5KP6tWG088",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patents = pd.read_csv(\"/content/drive/My Drive/data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcP2dxjsG1AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(patents.shape)\n",
        "\n",
        "patents.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7pxWKv-kU6n",
        "colab_type": "text"
      },
      "source": [
        "#### **l1 -> Non-Alcoholic** \n",
        "#### **l2 -> Alcoholic**\n",
        "#### **l3 -> Non-Autonomous**\n",
        "#### **l4 -> Autonomous**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi62cwHgG1Gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patents_labels = patents[[\"l1\", \"l2\", \"l3\", \"l4\"]]\n",
        "patents_labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5ByAkhFG1JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Total entries for diffrent classes\n",
        "\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 10\n",
        "fig_size[1] = 8\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "\n",
        "patents_labels.sum(axis=0).plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUnIe7DHKILr",
        "colab_type": "text"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybpuLsqeG1MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def preprocess_text(sen):\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC2-I4eoG1O9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "sentences = list(patents[\"title\"])\n",
        "for sen in sentences:\n",
        "    X.append(preprocess_text(sen))\n",
        "\n",
        "y = patents_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbYVHNOG1R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzoRTHz1G1VM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "maxlen = 200\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7TeY7o1J7wV",
        "colab_type": "text"
      },
      "source": [
        "### Pre-Trained Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSYtiQZpG1ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-Trained\n",
        "\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open('/content/drive/My Drive/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()\n",
        "\n",
        "embedding_matrix = zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VOoGBkvKTdy",
        "colab_type": "text"
      },
      "source": [
        "### Sequential Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvaoVdtwG1bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deep_inputs = Input(shape=(maxlen,))\n",
        "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
        "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
        "dense_layer_1 = Dense(4, activation='sigmoid')(LSTM_Layer_1)\n",
        "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tnVt0mXKk1q",
        "colab_type": "text"
      },
      "source": [
        "##### Summary and Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mUoGcjqG1fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SvPfHbLKsLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9V0AttqK73k",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7LIIgBhKsOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty3zWtQCKsRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "\n",
        "print(\"Test Score:\", score[0])\n",
        "print(\"Test Accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}